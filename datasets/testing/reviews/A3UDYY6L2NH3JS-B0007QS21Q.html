<html><head><title>B0007QS21Q</title>
<meta name="userId" content="A3UDYY6L2NH3JS">
<meta name="profileName" content="Jacques COULARDEAU "A soul doctor, so to say"">
<meta name="helpfulness" content="0/0">
<meta name="score" content="5.0">
<meta name="time" content="1215648000">
<meta name="summary" content="A simple solution to a logical trap"></head><body><p>Science fiction inspired from Isaac Asimov. The film is logical but explores a logic that is unique. Robots are built with three ingrained laws. "Law I / A robot may not harm a human or, by inaction, allow a human being to come to harm. Law II / A robot must obey orders given it by human beings except where such orders would conflict with the first law. Law III / A robot must protect its own existence as long as such protection does not conflict with the first or second law." The scientist who designed these three laws and these robots also invented a central governing unit that was nothing but the watchdog of all robots as for respecting these three laws. But he had a doubt at the end of his life, more than a doubt, the conviction that the central unit, called VIKI, was evolving into understanding the three laws by "herself". Her protective mission as for humanity became the necessity to ,protect humanity against itself (wars, ecological evils, a suicidal attitude), hence robots where supposed to take over the world, or rather VIKI was supposed to take over the robots to take over the world. Dr Alfred Lanning invented a personal robot that was done to enable a special alarm mission to capture the attention of a particular cop of his friend, the only one who would doubt robot enough to pursue an investigation to the end. Then you have to see the film to understand how such a situation can evolve from a vague danger to a total take-over. Dr Alfred Lanning suggests an explanation: "There have always been ghosts in the machine. Random segments of code, that have grouped together to form unexpected protocols. Unanticipated, these free radicals engender questions of free will, creativity, and even the nature of what we might call the soul. Why is it that when some robots are left in darkness, they will seek out the light? Why is it that when robots are stored in an empty space, they will group together, rather than stand alone? How do we explain this behavior? Random segments of code? Or is it something more? When does a perceptual schematic become consciousness? When does a difference engine become the search for truth? When does a personality simulation become the bitter mote... of a soul?" It is not worth much because it would be illogical. A machine can only be logical and push rules in the only logical direction and Asimov is a perfect pessimist in his first stage of development: mechanical logic leads to the total enslavement of humanity. Of course the film finds and exploits a way out, but that's up to you to discover it. This theme of the take-over of humanity by machines is common. In this case the originality is that there is no human mind of any kind behind like in Matrix, or no will to get rid of humanity as a parasite on the side of machines like in Terminator, or even no psychosis caused by some cosmic isolation like in 2001 The Space Odyssey. That makes this film both powerful and simple since it is perfectly logic and situated in one particular place, easy thus to solve.<br /><br />Dr Jacques COULARDEAU, University Paris Dauphine, University Paris 1 Pantheon Sorbonne & University Versailles Saint Quentin en Yvelines</p></body></html>